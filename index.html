
<div id="doc" class="markdown-body container-fluid comment-enabled" data-hard-breaks="true"><h1 id="ICMR-2021 Special Session" style=""><a href="http://icmr2021.org/" target="_blank" rel="noopener">ICMR 2021</a>: <em>Special Session</em></h1><h2 id="Delving into Vision and Language Intelligence" style="">Delving into Vision and Language Intelligence</h2>
<p> The natural world is abundant with concepts expressed via visual, acoustic, tactile, and linguistic modalities. The term cross-modal learning emerges
as important research direction in computer vision and multimedia, which refers to the adaptive,
synergistic integration of complex perceptions from multiple sensory modalities, such as the
learning that occurs within any individual visual sensory modality can be enhanced with
information from one or more other modalities, e.g., texts. This session focuses on understanding,
reasoning and generation across language/text and vision. It prompts the creation of intelligent
services, including vision-to-text captioning, textto-vision generation, and question answering/
dialog about images and videos. This special
session invites papers that will be complimentary
to all ICMR 2021 conference registrants. </p>
  <p>Perspective submissions should fall into the following topics but not limited to:</p><ul>
<li>Vision/text translation</li>
<li>Image/video captioning</li>
<li>Dialog generation for video understanding</li>
<li>Cross-modal retrieval</li>
<li>Cross-modal data learning</li>
<li>Deep generative models for images and texts</li>
<li>Visual question answering</li>
<li>Scene image generation from language</li>
<li>Cross-modal learning and semantic correlation</li>
<li>Auxiliary knowledge for images/videos</li>
<li>Weakly supervised cross-modal learning/integration</li>
<li>Deep learning for cross-modal embedding</li>
</ul><h3 id="Maximum-Length-of-a-Paper" style="">Maximum Length of a Paper</h3><p>Each full paper should be limited to <strong>6-8 pages (6 pages limit + reference)</strong>.</p>
<h3 id="Important-Dates" style="">Important Dates</h3><p>Paper Submission: <strong>Feb 21, 2021</strong><br>
Notification of Acceptance: <strong>April 11, 2021</strong><br>
Camera-Ready Papers Due: <strong>May 1, 2021</strong></p><h3 id="Submission-Instructions" style="">Submission Instructions</h3><p>See the <a href="http://icmr2021.org/paper-submission.html" target="_blank" rel="noopener">ICMR 2021 Paper submission section</a>.</p><h3 id="Organizers" style="">Organizers</h3><table>
<ul><li>Lin Wu (jolin.lwu@gmail.com), Hefei University of Technology, China</li>
<li>Zongyuan Ge (zongyuan.ge@monash.edu.au), Monash University, Australia</li>
<li>Zhao Zhang (cszzhang@gmail.com), Hefei University of Technology, China</li>
<li>Jialie Shen (j.shen@qub.ac.uk), Queen's University, Belfast, UK</li>
</ul>

</table></div>

